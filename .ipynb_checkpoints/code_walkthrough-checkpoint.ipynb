{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25850a58-94b3-4c28-a84f-8997eb090008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cba7e9-8bab-41d1-9ea6-435eae68f7a4",
   "metadata": {},
   "source": [
    "# Code Demo/Walkthrough\n",
    "\n",
    "Contents:\n",
    "1. [Cleaned version](#cleaned-code)\n",
    "2. [UX improvements](#ux)\n",
    "3. [External files](#extra-files)\n",
    "4. Nonneural tweaks\n",
    "5. The results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c002e23-f89f-4b60-a11d-eaf61169bdd4",
   "metadata": {},
   "source": [
    "<a id='cleaned-code'></a>\n",
    "### Cleaned Code (nonneural_myteam.py)\n",
    "\n",
    "We decided to rewrite the original nonneural.py code from scratch, really just to see how well we understood it, and in the process decided that a lot of what they had written was not very nice. The goal of this notebook is not really to explain the full extent of the minor tweaks, but some of them feel significant enough to mention:\n",
    "\n",
    "#### Levenshtein memoizer\n",
    "\n",
    "Their version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f009f0f-d173-4886-901e-cacd86874926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN ME\n",
    "\n",
    "def memolrec(func):\n",
    "    \"\"\"Memoizer for Levenshtein.\"\"\"\n",
    "    cache = {}\n",
    "    \n",
    "    def wrap(sp, tp, sr, tr, cost):\n",
    "        if (sr,tr) not in cache:\n",
    "            res = func(sp, tp, sr, tr, cost) # why call it using the past values...\n",
    "            \n",
    "            cache[(sr,tr)] = (res[0][len(sp):], res[1][len(tp):], res[4] - cost)\n",
    "            # ...only to immediately remove them from the output?\n",
    "            \n",
    "        return sp + cache[(sr,tr)][0], tp + cache[(sr,tr)][1], '', '', cost + cache[(sr,tr)][2]\n",
    "    \n",
    "    return wrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3c9c6e-8fd2-4f28-9364-e24393094397",
   "metadata": {},
   "source": [
    "Our version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5b5e1a-090c-4cbf-91d0-fea7499fed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN ME EITHER\n",
    "def memolrec(func):\n",
    "    \"\"\"Wrapper function/memoizer for recursive levenshtein implementation. Returns 'decorated' version\n",
    "    of levenshtein.\"\"\"\n",
    "\n",
    "    cache = {}\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrap(spast, tpast, srem, trem, cost):\n",
    "        \n",
    "        if (srem, trem) not in cache:\n",
    "            res = func('', '', srem, trem, 0) # this function call does not need to know the previous values\n",
    "            \n",
    "            cache[(srem, trem)] = (res[0], res[1], res[4]) # now this line can directly store the output\n",
    "        \n",
    "        aln_srem, aln_trem, rem_cost = cache[(srem, trem)]\n",
    "        return spast+aln_srem, tpast+aln_trem, '', '', cost + rem_cost\n",
    "    \n",
    "    return wrap # return decorated function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3249a-020b-47bf-b195-6c7e4225c4b5",
   "metadata": {},
   "source": [
    "It might seem trivial, but for whatever reason, we noticed the original code had a really odd tendency to\n",
    "insert a bunch of characters before the final 'r' when aligning a lemma and a form, even if the inflected\n",
    "form had no r's in the suffix (like 'abjure___r__' to 'abjurassions'). This had no significant impact on the\n",
    "ultimate performance of the code, but curiously when run with none of our other changes, it actually guesses correctly on exactly one extra word (an inflected form of ouÃ¯r).\n",
    "\n",
    "#### Prefix and suffix redundancies\n",
    "\n",
    "This was part of the assignment, but I was personally a fan of this change because it made so much of the code look a lot nicer. We established two global constants (so as to prevent potential difficult-to-track-down typos from hard-coding the values everywhere)\n",
    "```python\n",
    "...\n",
    "# global constants\n",
    "PRE = 0\n",
    "SUF = 1\n",
    "...\n",
    "```\n",
    "and then everything that involved storing prefix/suffix rules in similar ways or applying almost identical algorithms to the same thing twice could be done a bit more elegantly with lists/tuples/for-loops, e.g.\n",
    "```python\n",
    "rules[PRE].add((inpre, outpre))\n",
    "```\n",
    "or\n",
    "```python\n",
    "for fix in (PRE, SUF):\n",
    "    \n",
    "    if msd not in allrules[fix]:\n",
    "        ...\n",
    "```\n",
    "\n",
    "#### Command-line argument parsing\n",
    "\n",
    "We just love being able to define our own options/arguments and then later accessing them as object attributes! It is super neat. This also happens to be the recommended library for retrieving comman-line arguments in python3. The `getopt` module is designed for those who are accustomed to C-style option retrieval and too stubborn to change their ways. We, however, are young, and we believe in progress. The accepted practices of C programming won't keep us down!\n",
    "\n",
    "That's how this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4dc143-5637-475e-a6ee-40cfcd65dcad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# REST OF MAIN FUNCTION WAS HERE\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m     main(sys\u001b[38;5;241m.\u001b[39margv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN ME PLEASE!\n",
    "\n",
    "def main(argv):\n",
    "    options, remainder = getopt.gnu_getopt(argv[1:], 'ohp:', ['output','help','path='])\n",
    "    TEST, OUTPUT, HELP, path = False,False, False, '../data/' # I hate this kind of variable assignment, tbch\n",
    "    for opt, arg in options:\n",
    "        if opt in ('-o', '--output'):\n",
    "            OUTPUT = True\n",
    "        if opt in ('-t', '--test'):\n",
    "            TEST = True\n",
    "        if opt in ('-h', '--help'):\n",
    "            HELP = True\n",
    "        if opt in ('-p', '--path'):\n",
    "            path = arg\n",
    "\n",
    "    if HELP:\n",
    "        # there were a bunch of print statements here that you had to keep editing by hand\n",
    "        # every time you wanted to add new options\n",
    "        pass\n",
    "    \n",
    "    # REST OF MAIN FUNCTION WAS HERE\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc0178-7c6a-4ed0-8993-f087f28decca",
   "metadata": {},
   "source": [
    "became this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f74ed-c132-43bf-b977-36d48a7bbe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I KNOW I'M COOL, BUT DON'T RUN ME EITHER\n",
    "\n",
    "def main(parsed):\n",
    "    # wow, i'm so neat and uncluttered\n",
    "    out = parsed.out\n",
    "    evl_ext = parsed.eval # and then access it here! (see below)\n",
    "    path = parsed.path\n",
    "    \n",
    "    # no help print-statements? no problem! the argparse library takes care of it for you!\n",
    "    \n",
    "    # REST OF MAIN FUNCTION WAS HERE\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(prog='NonNeuralMyTeam',\n",
    "                                     description='Our cleaned and very slightly edited version'\n",
    "                                        + ' of the original nonneural.py code.',\n",
    "                                     epilog='Generating this help message was done with the argparse library'\n",
    "                                        + ' instead of manually with a bunch of print-statements.')\n",
    "    \n",
    "    parser.add_argument('-o', '--output',\n",
    "                        dest='out',\n",
    "                        action='store_true',\n",
    "                        help='generate output files with guesses. files are written to the same place as'\n",
    "                            + ' the path argument (or default value if no path was specified) under <lang>.out')\n",
    "    parser.add_argument('-t', '--test',\n",
    "                        dest='eval', # look, see? you can tell it what the variable is called (see above)\n",
    "                        action='store_const',\n",
    "                        const='.tst',\n",
    "                        default='.dev',\n",
    "                        help='evaluate models on test instead of dev data.')\n",
    "    parser.add_argument('-p', '--path',\n",
    "                        dest='path',\n",
    "                        default='data',\n",
    "                        help='path to the directory containing data files. defaults to \\'data\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb1745c-51d1-4f36-af64-cfdc57fee499",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='ux'></a>\n",
    "### UX improvements: debug mode, diff checkers, and more!\n",
    "\n",
    "\\[INSERT SOME STUFF\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d5437-7b95-416d-acc9-0ba2c1a12a79",
   "metadata": {},
   "source": [
    "<a id='extra-files'></a>\n",
    "### Added files and scripts\n",
    "\n",
    "#### Wiktionary scrape for Old/Middle French\n",
    "A major aspect of our improvements to the code was simply filtering out all the Old and Middle French from the data; however, this required reading each lemma's wiktionary page to figure out whether each word was in fact modern French. We wrote `mark-data.sh` to automate this task and generate CSV files containing information on what period of French each lemma came from (as well as whether it was a dated or obsolete but still relatively modern term).\n",
    "\n",
    "(An excerpt containing the if-statement that assigns the categories)\n",
    "```bash\n",
    "    if [[ $(grep '^French' tmp2) ]] ; then\n",
    "        if [[ $(ggrep -P '<span class=\\\"usage-label-sense((?<!<a).)*<a[^>]*>dated<' tmp) ]] ; then\n",
    "            echo \"$line,dtd\" >> \"tmp-marked.csv\"\n",
    "        elif [[ $(grep 'Category:French obsolete forms' tmp) ]] ; then\n",
    "            echo \"$line,obs\" >> \"tmp-marked.csv\"\n",
    "        else\n",
    "            echo \"$line,-\" >> \"tmp-marked.csv\"\n",
    "        fi\n",
    "    else\n",
    "        if [[ $(grep 'Middle French' tmp2) ]] && [[ $(grep 'Old French' tmp2) ]] ; then\n",
    "            echo \"$line,M-O\" >> \"tmp-marked.csv\"\n",
    "        elif [[ $(grep 'Middle French' tmp2) ]] ; then\n",
    "            echo \"$line,M\" >> \"tmp-marked.csv\"\n",
    "        else\n",
    "            echo \"$line,O\" >> \"tmp-marked.csv\"\n",
    "        fi\n",
    "    fi\n",
    "```\n",
    "\n",
    "This script runs `cut -f 1` on the desired data file, then pipes it to `sort` and `uniq` to get a list of unique lemmas from the file, and then `curl`s each wiktionary page using by adding the lemma to the base url `'https://en.wiktionary.org/wiki/'`. It then uses `grep` and the regular expression `<span class=\\\"mw-headline[^>]*>[^<]*<` to get all the section headlines (i.e., all the languages the word exists in), and checks whether the stand-alone string 'French' is one of the headlines. (Note: for at least one word, there was the additional complication that the lemma had been faithfully inherited from Middle French, but the conjugation rules had changed, but we did not have time to work out this issue once it was discovered).\n",
    "\n",
    "#### The CSV files\n",
    "\n",
    "The script from above produced simple CSV files that we could later load into a dictionary in our `nonneural.py` program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "153cc19e-73db-42df-a93f-beadd957a19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarked-fra.trn.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(csvfile[::\u001b[38;5;241m100\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('data','marked-fra.trn.csv')) as csvfile:\n",
    "    csvlines = [line for line in csvfile if line != '\\n']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
